{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StyleTransfer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junwin/StyleTransferTensorflow/blob/main/StyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScitaPqhKtuW"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvztxQ6VsK2k"
      },
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXlcl8lqBgAD"
      },
      "source": [
        "# Fast Style Transfer for Arbitrary Styles\n",
        "![Alt text](https://junwin.github.io/assets/stylizedMatisseTreeTiny.jpeg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " \n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeeuYzbZcJzs"
      },
      "source": [
        "Based on the model code in [magenta](https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization) and the publication:\n",
        "\n",
        "[Exploring the structure of a real-time, arbitrary neural artistic stylization\n",
        "network](https://arxiv.org/abs/1705.06830).\n",
        "*Golnaz Ghiasi, Honglak Lee,\n",
        "Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens*,\n",
        "Proceedings of the British Machine Vision Conference (BMVC), 2017.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaM8BVxrCA2E"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J65jog2ncJzt"
      },
      "source": [
        "Let's start with importing TF-2 and all relevant dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-KXRY5XBu2u"
      },
      "source": [
        "import functools\n",
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"TF-Hub version: \", hub.__version__)\n",
        "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
        "print(\"GPU available: \", tf.test.is_gpu_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "467AVDSuzBPc"
      },
      "source": [
        "# Load TF-Hub module.\n",
        "\n",
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsoDv_9geoZn"
      },
      "source": [
        "# @title Define image loading and visualization functions  { display-mode: \"form\" }\n",
        "\n",
        "def crop_center(image):\n",
        "  \"\"\"Returns a cropped square image.\"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape)\n",
        "  return image\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img = plt.imread(image_path).astype(np.float32)[np.newaxis, ...]\n",
        "  if img.max() > 1.0:\n",
        "    img = img / 255.\n",
        "  if len(img.shape) == 3:\n",
        "    img = tf.stack([img, img, img], axis=-1)\n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  return img\n",
        "\n",
        "\n",
        "def load_image_file(image_path, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  #image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img = plt.imread(image_path).astype(np.float32)[np.newaxis, ...]\n",
        "  if img.max() > 1.0:\n",
        "    img = img / 255.\n",
        "  if len(img.shape) == 3:\n",
        "    img = tf.stack([img, img, img], axis=-1)\n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  return img\n",
        "\n",
        "def show_n(images, titles=('',)):\n",
        "  n = len(images)\n",
        "  image_sizes = [image.shape[1] for image in images]\n",
        "  w = (image_sizes[0] * 6) // 320\n",
        "  plt.figure(figsize=(w  * n, w))\n",
        "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
        "  for i in range(n):\n",
        "    plt.subplot(gs[i])\n",
        "    plt.imshow(images[i][0], aspect='equal')\n",
        "    plt.axis('off')\n",
        "    plt.title(titles[i] if len(titles) > i else '')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8etHh05-CJHc"
      },
      "source": [
        "Let's get as well some images to play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRc0vat3Alzo"
      },
      "source": [
        "# @title Load example images  { display-mode: \"form\" }\n",
        "\n",
        "content_image_url = '/content/drive/MyDrive/ColabData/oldmasterphoto.jpg'  # @param {type:\"string\"}\n",
        "style_image_url = '/content/drive/MyDrive/ColabData/matisse1.jpg'  # @param {type:\"string\"}\n",
        "output_image_size = 512  # @param {type:\"integer\"}\n",
        "\n",
        "# The content image size can be arbitrary.\n",
        "content_img_size = (output_image_size, output_image_size)\n",
        "# The style prediction model was trained with image size 256 and it's the \n",
        "# recommended image size for the style image (though, other sizes work as \n",
        "# well but will lead to different results).\n",
        "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "content_image = load_image_file(content_image_url, content_img_size)\n",
        "style_image = load_image_file(style_image_url, style_img_size)\n",
        "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "show_n([content_image, style_image], ['Content image', 'Style image'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnAv-F3O9fLV"
      },
      "source": [
        "# Stylize content image with given style image.\n",
        "# This is pretty fast within a few milliseconds on a GPU.\n",
        "\n",
        "outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "stylized_image = outputs[0]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5o_mXPduxOI"
      },
      "source": [
        "show_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs62lK6aw7Tx"
      },
      "source": [
        "To save your stylized image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzHhiZ6Lw-xc"
      },
      "source": [
        "save_img('/content/drive/MyDrive/ColabData/stylized.jpg', stylized_image[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dycDdQfSwX5g"
      },
      "source": [
        "If you need to use Google Drive to get at your data uncomment these and run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2JZZA7dK-KK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}